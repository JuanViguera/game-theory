{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo GT repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nashpy as nash\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "font = {'family' : 'sans-serif',\n",
    "    'weight' : 'normal',\n",
    "    'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-player 2-action games plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a game\n",
    "A = np.array([[3, 0], [5, 1]])\n",
    "B = np.array([[3, 5], [0, 1]])\n",
    "game = nash.Game(A, B) #prisioner's dilemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gt_utils.two_pa.plot_utils.plots import UtilityPloter\n",
    "utility_plotter = UtilityPloter(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##interactive utility of first player\n",
    "#Note: Zoom out with right-click\n",
    "#Note: Notation explained in detail in the source code\n",
    "%matplotlib ipympl\n",
    "fig_objects = utility_plotter.make_2d_plots(player=1) #utility of player 1 vs probability of player 2 of playing the first action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##non-interactive utility of second player\n",
    "plt.close(fig_objects[0]) #avoids showing previous plot when changing from interactive to non-interactive plot\n",
    "%matplotlib inline\n",
    "fig_objects = utility_plotter.make_2d_plots(player=2) #utility of player 2 vs probability of player 1 of playing the first action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking NE with nashpy\n",
    "equilibria = game.support_enumeration()\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute NE for aribritary number of actions: Support enumeration\n",
    "A = [[1,1,-1], [2,-1,0]]\n",
    "B = [[1./2,-1,-1./2], [-1,3,2]]\n",
    "\n",
    "game2 = nash.Game(A, B) #2x3 game\n",
    "equilibria = game2.support_enumeration() #if support enumeration is too slow, there are more advanced algorithms available in nashpy\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d utility plots\n",
    "%matplotlib ipympl\n",
    "fig_objects = utility_plotter.make_3d_plots(player=1) #utility of player 1 vs probability of player 1 of playing the first action and probability of player 2 of playing the first action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig_objects[0])\n",
    "%matplotlib ipympl\n",
    "fig_objects = utility_plotter.make_3d_plots(player=2) #utility of player 2 vs probability of player 1 of playing the first action and probability of player 2 of playing the first action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saddle point in matching pennies\n",
    "plt.close(fig_objects[0])\n",
    "\n",
    "matching_pennies = nash.Game(np.array([[1, -1], [-1, 1]]))\n",
    "utility_plotter_mp = UtilityPloter(matching_pennies)\n",
    "plt.close(fig_objects[0])\n",
    "%matplotlib ipympl\n",
    "fig_objects = utility_plotter_mp.make_3d_plots(player=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folk theorem plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gt_utils.two_pa.plot_utils.plots import FolkPlotter\n",
    "plt.close(fig_objects[0])\n",
    "%matplotlib inline\n",
    "folk_plotter = FolkPlotter(game)\n",
    "fig_objects = folk_plotter.make_folk_plot() #generate feasible payoffs polygon and marks min max value value for each player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicator dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hawk-dove\n",
    "A = np.array([[-2, 6], [0, 3]])\n",
    "B = np.array([[-2, 0], [6, 3]])\n",
    "hawk_dove = nash.Game(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population of doves and few hawks\n",
    "y0 = np.array([0.05, 0.95])#initial population\n",
    "timepoints = np.linspace(0, 10, 1500)\n",
    "hawk_population, dove_population = hawk_dove.replicator_dynamics(y0=y0, timepoints=timepoints).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig_objects[0])\n",
    "%matplotlib ipympl\n",
    "\n",
    "fig_objects = plt.subplots()\n",
    "\n",
    "fig_objects[1].plot(hawk_population, label=\"Hawks\")\n",
    "fig_objects[1].plot(dove_population, label=\"Doves\")\n",
    "fig_objects[1].set_ylim(0, 1)\n",
    "fig_objects[1].set_ylabel(\"Population proportion\")\n",
    "fig_objects[1].set_xlabel(\"Time\")\n",
    "fig_objects[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciating games in extentensive form and visualizing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigtree import Node\n",
    "from gt_utils.extensive.extensive import ExtensiveFormGame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#available actions must be encoded in the node names!!\n",
    "\n",
    "#big mokey-little monkey\n",
    "\n",
    "BMlm_root = Node(\"root\")\n",
    "C = Node(\"C\", parent=BMlm_root)\n",
    "W = Node(\"W\", parent=BMlm_root)\n",
    "Cc = Node(\"Cc\", payoff=[5,3], parent=C)\n",
    "Cw = Node(\"Cw\", payoff= [4,4], parent=C)\n",
    "Wc = Node(\"Wc\", payoff=[9,1], parent=W)\n",
    "Ww = Node(\"Ww\", payoff = [0,0], parent=W)\n",
    "\n",
    "BMlm_game = ExtensiveFormGame(BMlm_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMlm_root.show(attr_list=[\"payoff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMlm_root.hshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extensive to normal form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_strategies = BMlm_game.enumerate_pure_strategies()\n",
    "u1, u2 = BMlm_game.get_normal_form() #creates a naspy game object in ExtensiceFormGame.nashpy_game\n",
    "\n",
    "print(pure_strategies[0])\n",
    "print(pure_strategies[1], \"\\n\")\n",
    "\n",
    "print(u1)\n",
    "print(u2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution is\n",
    "\n",
    "![title](resources/BMlm_normal_form.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Nash Equilibria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equilibria = BMlm_game.nashpy_game.support_enumeration() #note: get_normal_form needs to be called before computing NE\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing payoff of Sub-game Perfect Equilibria: backward induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMlm_game.backward_induction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more exotic extensive-form game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exotic bMlm\n",
    "\n",
    "root = Node(\"root\")\n",
    "C = Node(\"C\", parent=root, payoff=[1,2])\n",
    "M = Node(\"M\", parent=root, payoff=[3,4])\n",
    "W = Node(\"W\", parent=root)\n",
    "Wc = Node(\"Wc\", payoff=[9,1], parent=W)\n",
    "Ww = Node(\"Ww\", parent=W)\n",
    "WwC = Node(\"WwC\", payoff=[4,5], parent=Ww)\n",
    "WwW = Node(\"WwW\", parent=Ww)\n",
    "WwWc = Node(\"WwWc\", payoff=[2,3], parent=WwW)\n",
    "WwWw = Node(\"WwWw\", parent=WwW)\n",
    "WwWwC = Node(\"WwWwC\", payoff=[7,8], parent=WwWw)\n",
    "WwWwW = Node(\"WwWwW\", payoff=[9,10], parent=WwWw)\n",
    "\n",
    "ext_game = ExtensiveFormGame(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_game.root.show(attr_list=[\"payoff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_strategies = ext_game.enumerate_pure_strategies()\n",
    "u1, u2 = ext_game.get_normal_form()\n",
    "\n",
    "print(pure_strategies[0])\n",
    "print(pure_strategies[1], \"\\n\")\n",
    "\n",
    "print(u1)\n",
    "print(u2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equilibria = ext_game.nashpy_game.support_enumeration() #note: get_normal_form needs to be called before computing NE\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_game.backward_induction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nashpy.repeated_games as create_repeated_games\n",
    "#matching pennies\n",
    "A = np.array([[1, -1], [-1, 1]])\n",
    "matching_pennies = nash.Game(A)\n",
    "\n",
    "repeated_game = create_repeated_games.obtain_repeated_game(game=matching_pennies, repetitions=2)\n",
    "\n",
    "print(repeated_game.payoff_matrices[0].shape)\n",
    "equilibrium = repeated_game.linear_program()\n",
    "print(equilibrium)\n",
    "stategies = create_repeated_games.obtain_strategy_space(A=A, repetitions=2)\n",
    "print(next(stategies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
